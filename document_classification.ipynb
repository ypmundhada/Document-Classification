{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "c6_ZrMOy7HCv",
    "outputId": "ba322dd0-bd15-4bae-cc1a-8734a780a318"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-811874fc-6cc8-4175-9ae1-001c69f180cb\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>space_73.txt</td>\n",
       "      <td>Last-modified: $Date: 93/04/01 14:39:10 $    ...</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>space_33.txt</td>\n",
       "      <td>&gt;In article &lt;5APR199318045045@kelvin.jpl.nasa...</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>space_5.txt</td>\n",
       "      <td>for sounding rockets? Thanks in advance, Jim.</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>space_8.txt</td>\n",
       "      <td>&gt;jmcocker@eos.ncsu.edu (Mitch) writes: &gt;&gt;effe...</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>space_66.txt</td>\n",
       "      <td>o The Faint Object Spectrograph (FOS) wa...</td>\n",
       "      <td>space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>business_79.txt</td>\n",
       "      <td>US interest rates are expected to rise for t...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>business_61.txt</td>\n",
       "      <td>House prices fell further in November and pr...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>business_52.txt</td>\n",
       "      <td>The UK manufacturing sector will continue to...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>business_13.txt</td>\n",
       "      <td>Japanese industry is growing faster than exp...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>business_5.txt</td>\n",
       "      <td>Struggling Japanese car maker Mitsubishi Mot...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-811874fc-6cc8-4175-9ae1-001c69f180cb')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-811874fc-6cc8-4175-9ae1-001c69f180cb button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-811874fc-6cc8-4175-9ae1-001c69f180cb');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                file                                               text  \\\n",
       "0       space_73.txt   Last-modified: $Date: 93/04/01 14:39:10 $    ...   \n",
       "1       space_33.txt   >In article <5APR199318045045@kelvin.jpl.nasa...   \n",
       "2        space_5.txt      for sounding rockets? Thanks in advance, Jim.   \n",
       "3        space_8.txt   >jmcocker@eos.ncsu.edu (Mitch) writes: >>effe...   \n",
       "4       space_66.txt        o The Faint Object Spectrograph (FOS) wa...   \n",
       "..               ...                                                ...   \n",
       "995  business_79.txt    US interest rates are expected to rise for t...   \n",
       "996  business_61.txt    House prices fell further in November and pr...   \n",
       "997  business_52.txt    The UK manufacturing sector will continue to...   \n",
       "998  business_13.txt    Japanese industry is growing faster than exp...   \n",
       "999   business_5.txt    Struggling Japanese car maker Mitsubishi Mot...   \n",
       "\n",
       "        label  \n",
       "0       space  \n",
       "1       space  \n",
       "2       space  \n",
       "3       space  \n",
       "4       space  \n",
       "..        ...  \n",
       "995  business  \n",
       "996  business  \n",
       "997  business  \n",
       "998  business  \n",
       "999  business  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"data.xlsx\")\n",
    "df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qacrkCpJ7XTV",
    "outputId": "b5b02019-cbf6-4f82-fd04-8e20c2a5c419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "cW04lwv178F2",
    "outputId": "66668ce3-7b23-4d86-d6e7-76e657459520"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-da62e9db-4e0e-4587-a1be-edf164d4a58e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>space_73.txt</td>\n",
       "      <td>Last-modified: $Date: 93/04/01 14:39:10 $    ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>space_33.txt</td>\n",
       "      <td>&gt;In article &lt;5APR199318045045@kelvin.jpl.nasa...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>space_5.txt</td>\n",
       "      <td>for sounding rockets? Thanks in advance, Jim.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>space_8.txt</td>\n",
       "      <td>&gt;jmcocker@eos.ncsu.edu (Mitch) writes: &gt;&gt;effe...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>space_66.txt</td>\n",
       "      <td>o The Faint Object Spectrograph (FOS) wa...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>business_79.txt</td>\n",
       "      <td>US interest rates are expected to rise for t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>business_61.txt</td>\n",
       "      <td>House prices fell further in November and pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>business_52.txt</td>\n",
       "      <td>The UK manufacturing sector will continue to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>business_13.txt</td>\n",
       "      <td>Japanese industry is growing faster than exp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>business_5.txt</td>\n",
       "      <td>Struggling Japanese car maker Mitsubishi Mot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da62e9db-4e0e-4587-a1be-edf164d4a58e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-da62e9db-4e0e-4587-a1be-edf164d4a58e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-da62e9db-4e0e-4587-a1be-edf164d4a58e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                file                                               text  label\n",
       "0       space_73.txt   Last-modified: $Date: 93/04/01 14:39:10 $    ...      7\n",
       "1       space_33.txt   >In article <5APR199318045045@kelvin.jpl.nasa...      7\n",
       "2        space_5.txt      for sounding rockets? Thanks in advance, Jim.      7\n",
       "3        space_8.txt   >jmcocker@eos.ncsu.edu (Mitch) writes: >>effe...      7\n",
       "4       space_66.txt        o The Faint Object Spectrograph (FOS) wa...      7\n",
       "..               ...                                                ...    ...\n",
       "995  business_79.txt    US interest rates are expected to rise for t...      0\n",
       "996  business_61.txt    House prices fell further in November and pr...      0\n",
       "997  business_52.txt    The UK manufacturing sector will continue to...      0\n",
       "998  business_13.txt    Japanese industry is growing faster than exp...      0\n",
       "999   business_5.txt    Struggling Japanese car maker Mitsubishi Mot...      0\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Fx7PnOSCg8i",
    "outputId": "6c198644-1354-43aa-881d-ebafea86af1d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "def lemmatization(text):\n",
    "  lemmatizer = WordNetLemmatizer();\n",
    "  txt_lmt = [lemmatizer.lemmatize(txt) for txt in text]\n",
    "  return txt_lmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5rc_ICL8gKW"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "def stemming(text):\n",
    "    stemmer = PorterStemmer() \n",
    "    txt_stm = [stemmer.stem(txt) for txt in text]\n",
    "    return txt_stm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "wNiltKhD7rzc",
    "outputId": "493b115a-585b-4a8b-e839-e673cf13b292"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-2d8dc73e-7f75-40b8-8da2-5dc9c9b93456\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>text_stem</th>\n",
       "      <th>text_lemmatize</th>\n",
       "      <th>t_stm_join</th>\n",
       "      <th>t_lmt_join</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>space_73.txt</td>\n",
       "      <td>7</td>\n",
       "      <td>[lastmodifi, date, seri, link, messag, period,...</td>\n",
       "      <td>[lastmodified, date, series, linked, message, ...</td>\n",
       "      <td>lastmodifi date seri link messag period post u...</td>\n",
       "      <td>lastmodified date series linked message period...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>space_33.txt</td>\n",
       "      <td>7</td>\n",
       "      <td>[articl, baalk, kelvinjplnasagov, ron, baalk, ...</td>\n",
       "      <td>[article, baalke, kelvinjplnasagov, ron, baalk...</td>\n",
       "      <td>articl baalk kelvinjplnasagov ron baalk write ...</td>\n",
       "      <td>article baalke kelvinjplnasagov ron baalke wri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>space_5.txt</td>\n",
       "      <td>7</td>\n",
       "      <td>[sound, rocket, thank, advanc, jim]</td>\n",
       "      <td>[sounding, rocket, thanks, advance, jim]</td>\n",
       "      <td>sound rocket thank advanc jim</td>\n",
       "      <td>sounding rocket thanks advance jim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>space_8.txt</td>\n",
       "      <td>7</td>\n",
       "      <td>[jmcocker, eosncsuedu, mitch, write, effect, o...</td>\n",
       "      <td>[jmcocker, eosncsuedu, mitch, writes, effect, ...</td>\n",
       "      <td>jmcocker eosncsuedu mitch write effect one ssr...</td>\n",
       "      <td>jmcocker eosncsuedu mitch writes effect one ss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>space_66.txt</td>\n",
       "      <td>7</td>\n",
       "      <td>[faint, object, spectrograph, fo, use, make, u...</td>\n",
       "      <td>[faint, object, spectrograph, fo, used, make, ...</td>\n",
       "      <td>faint object spectrograph fo use make ultravio...</td>\n",
       "      <td>faint object spectrograph fo used make ultravi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>business_79.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[us, interest, rate, expect, rise, fifth, time...</td>\n",
       "      <td>[u, interest, rate, expected, rise, fifth, tim...</td>\n",
       "      <td>us interest rate expect rise fifth time sinc j...</td>\n",
       "      <td>u interest rate expected rise fifth time since...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>business_61.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[hous, price, fell, novemb, properti, sale, ti...</td>\n",
       "      <td>[house, price, fell, november, property, sale,...</td>\n",
       "      <td>hous price fell novemb properti sale time leng...</td>\n",
       "      <td>house price fell november property sale time l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>business_52.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[uk, manufactur, sector, continu, face, seriou...</td>\n",
       "      <td>[uk, manufacturing, sector, continue, face, se...</td>\n",
       "      <td>uk manufactur sector continu face seriou chall...</td>\n",
       "      <td>uk manufacturing sector continue face serious ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>business_13.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[japanes, industri, grow, faster, expect, boos...</td>\n",
       "      <td>[japanese, industry, growing, faster, expected...</td>\n",
       "      <td>japanes industri grow faster expect boost hope...</td>\n",
       "      <td>japanese industry growing faster expected boos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>business_5.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[struggl, japanes, car, maker, mitsubishi, mot...</td>\n",
       "      <td>[struggling, japanese, car, maker, mitsubishi,...</td>\n",
       "      <td>struggl japanes car maker mitsubishi motor str...</td>\n",
       "      <td>struggling japanese car maker mitsubishi motor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d8dc73e-7f75-40b8-8da2-5dc9c9b93456')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2d8dc73e-7f75-40b8-8da2-5dc9c9b93456 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2d8dc73e-7f75-40b8-8da2-5dc9c9b93456');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                file  label  \\\n",
       "0       space_73.txt      7   \n",
       "1       space_33.txt      7   \n",
       "2        space_5.txt      7   \n",
       "3        space_8.txt      7   \n",
       "4       space_66.txt      7   \n",
       "..               ...    ...   \n",
       "995  business_79.txt      0   \n",
       "996  business_61.txt      0   \n",
       "997  business_52.txt      0   \n",
       "998  business_13.txt      0   \n",
       "999   business_5.txt      0   \n",
       "\n",
       "                                             text_stem  \\\n",
       "0    [lastmodifi, date, seri, link, messag, period,...   \n",
       "1    [articl, baalk, kelvinjplnasagov, ron, baalk, ...   \n",
       "2                  [sound, rocket, thank, advanc, jim]   \n",
       "3    [jmcocker, eosncsuedu, mitch, write, effect, o...   \n",
       "4    [faint, object, spectrograph, fo, use, make, u...   \n",
       "..                                                 ...   \n",
       "995  [us, interest, rate, expect, rise, fifth, time...   \n",
       "996  [hous, price, fell, novemb, properti, sale, ti...   \n",
       "997  [uk, manufactur, sector, continu, face, seriou...   \n",
       "998  [japanes, industri, grow, faster, expect, boos...   \n",
       "999  [struggl, japanes, car, maker, mitsubishi, mot...   \n",
       "\n",
       "                                        text_lemmatize  \\\n",
       "0    [lastmodified, date, series, linked, message, ...   \n",
       "1    [article, baalke, kelvinjplnasagov, ron, baalk...   \n",
       "2             [sounding, rocket, thanks, advance, jim]   \n",
       "3    [jmcocker, eosncsuedu, mitch, writes, effect, ...   \n",
       "4    [faint, object, spectrograph, fo, used, make, ...   \n",
       "..                                                 ...   \n",
       "995  [u, interest, rate, expected, rise, fifth, tim...   \n",
       "996  [house, price, fell, november, property, sale,...   \n",
       "997  [uk, manufacturing, sector, continue, face, se...   \n",
       "998  [japanese, industry, growing, faster, expected...   \n",
       "999  [struggling, japanese, car, maker, mitsubishi,...   \n",
       "\n",
       "                                            t_stm_join  \\\n",
       "0    lastmodifi date seri link messag period post u...   \n",
       "1    articl baalk kelvinjplnasagov ron baalk write ...   \n",
       "2                        sound rocket thank advanc jim   \n",
       "3    jmcocker eosncsuedu mitch write effect one ssr...   \n",
       "4    faint object spectrograph fo use make ultravio...   \n",
       "..                                                 ...   \n",
       "995  us interest rate expect rise fifth time sinc j...   \n",
       "996  hous price fell novemb properti sale time leng...   \n",
       "997  uk manufactur sector continu face seriou chall...   \n",
       "998  japanes industri grow faster expect boost hope...   \n",
       "999  struggl japanes car maker mitsubishi motor str...   \n",
       "\n",
       "                                            t_lmt_join  \n",
       "0    lastmodified date series linked message period...  \n",
       "1    article baalke kelvinjplnasagov ron baalke wri...  \n",
       "2                   sounding rocket thanks advance jim  \n",
       "3    jmcocker eosncsuedu mitch writes effect one ss...  \n",
       "4    faint object spectrograph fo used make ultravi...  \n",
       "..                                                 ...  \n",
       "995  u interest rate expected rise fifth time since...  \n",
       "996  house price fell november property sale time l...  \n",
       "997  uk manufacturing sector continue face serious ...  \n",
       "998  japanese industry growing faster expected boos...  \n",
       "999  struggling japanese car maker mitsubishi motor...  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "nltk.download('punkt')\n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df.apply(lambda x: re.sub('<[^>]*>', ' ', str(x.text)), axis=1)\n",
    "df['text'] = df.apply(lambda x: word_tokenize(x.text), axis=1)\n",
    "trnslt = str.maketrans('','', string.punctuation)\n",
    "df['text'] = df.apply(lambda x: [w.translate(trnslt) for w in x.text], axis=1)\n",
    "df['text'] = df.apply(lambda x: [w for w in x.text if w.isalpha()], axis=1)\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['text'] = df.apply(lambda x: [w for w in x.text if not w in stop_words], axis=1)\n",
    "df['text_stem'] = df['text'].apply(stemming)\n",
    "df['text_lemmatize'] = df['text'].apply(lemmatization)\n",
    "df['t_stm_join'] = df.apply(lambda x: ' '.join(x.text_stem), axis=1)\n",
    "df['t_lmt_join'] = df.apply(lambda x: ' '.join(x.text_lemmatize), axis=1)\n",
    "df.drop(columns=['text'],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-75BZ2-95b63"
   },
   "source": [
    "## **Preparing Data for models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qivjByjdCHE"
   },
   "source": [
    "Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QeoIlis6V2la",
    "outputId": "a3d8ac3f-602a-4dbc-baaf-3077fa93ee1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x20126 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 140776 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X = []\n",
    "for text in df['t_stm_join']:\n",
    "  X.append(text)\n",
    "cvec = CountVectorizer()\n",
    "x_cvec = cvec.fit_transform(X)\n",
    "x_cvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo8dSlC3dDhV"
   },
   "source": [
    "Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4xxNbOrb9fG",
    "outputId": "cc969713-f3cf-4616-fba2-f780f2a7b86b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x24993 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 146408 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X = []\n",
    "for text in df['t_lmt_join']:\n",
    "  X.append(text)\n",
    "cvec = CountVectorizer()\n",
    "x_cvec = cvec.fit_transform(X)\n",
    "x_cvec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2yzSED8TWp0"
   },
   "source": [
    "Data Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rGUn6l9VYQh"
   },
   "source": [
    "1) TF-IDF Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ia0lM43CD3k5",
    "outputId": "df7a5331-701e-4eac-e7c5-93d98c384a04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 20126)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "x = vec.fit(df['t_stm_join'])\n",
    "X_vec = vec.transform(df['t_stm_join'])\n",
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ip-qVzpbXtlp",
    "outputId": "97d2cd34-3ddb-4669-8ac6-521a05be5e71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (3.6.0)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.1 MB 127 kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.21.6)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (1.7.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim) (5.2.1)\n",
      "Installing collected packages: gensim\n",
      "  Attempting uninstall: gensim\n",
      "    Found existing installation: gensim 3.6.0\n",
      "    Uninstalling gensim-3.6.0:\n",
      "      Successfully uninstalled gensim-3.6.0\n",
      "Successfully installed gensim-4.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EEZc2enVVb9G"
   },
   "source": [
    "2) Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_g9NRXwYPPA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def W2V(obj,X):\n",
    "  ndim = len(obj.values())\n",
    "  vectors=[]\n",
    "  for documents in X:\n",
    "    vectors.append(np.mean([obj[words] for words in documents if words in obj]\n",
    "            or [np.zeros(ndim)],axis=0))\n",
    "  return np.array(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iCuL6MJwTsw0",
    "outputId": "3fa805fe-f596-48c5-9d91-5b60530097a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-63b5b5ef79da>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(vectors)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "X=df['text_stem'].tolist()\n",
    "model = gensim.models.Word2Vec(X,vector_size=100)\n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors))\n",
    "X_w2v = W2V(w2v,X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIhTyZj9fHh8"
   },
   "source": [
    "3) Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r9R0hFwQchWZ",
    "outputId": "c8d6743a-b5ae-46b3-bb59-a1a1c299eb64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n",
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "print(list(gensim.downloader.info()['models'].keys()))\n",
    "glove_vectors = gensim.downloader.load('word2vec-google-news-300')\n",
    "len(glove_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVLYydVofwTb"
   },
   "outputs": [],
   "source": [
    "X=df['text_stem'].tolist()\n",
    "X_from_vocab = [];\n",
    "for text in X:\n",
    "  X_from_vocab.append([txt for txt in text if txt in glove_vectors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2wZm6ES3TPV"
   },
   "outputs": [],
   "source": [
    "X_vec=[]\n",
    "for text in X_from_vocab:\n",
    "    X_vec.append(np.mean([glove_vectors[txt] for txt in text],axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pE0WrgDx6y2D",
    "outputId": "8988d69c-e556-40eb-9128-bf48afdf5301"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spaces', 0.6570690870285034),\n",
       " ('music_concept_ShockHound', 0.5850345492362976),\n",
       " ('Shuttle_docks', 0.5566749572753906),\n",
       " ('Space', 0.5478203296661377),\n",
       " ('Soviet_Union_Yuri_Gagarin', 0.5417766571044922),\n",
       " ('Shuttle_Discovery_blasts', 0.5352603197097778),\n",
       " ('Shuttle_Discovery_docks', 0.534925103187561),\n",
       " ('Shuttle_Endeavour_undocks', 0.532420814037323),\n",
       " ('Shuttle_Discovery_arrives', 0.5323426723480225),\n",
       " ('Shuttle_undocks', 0.523307740688324)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1vN95bTZ9B1I",
    "outputId": "70aa0a4a-799b-4e96-8643-44a2e769ab9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('traveling', 0.6823130249977112),\n",
       " ('Travel', 0.6577276587486267),\n",
       " ('travelers', 0.5849088430404663),\n",
       " ('trips', 0.5770835280418396),\n",
       " ('travels', 0.5704988241195679),\n",
       " ('trip', 0.569098174571991),\n",
       " ('journeys', 0.5535728335380554),\n",
       " ('airfare', 0.5398489832878113),\n",
       " ('Travelling', 0.5369202494621277),\n",
       " ('Traveling', 0.5305294394493103)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.most_similar('travel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3v0uCtb9muT"
   },
   "source": [
    "# **PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBWdzCi89JX9"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "pca = TruncatedSVD(n_components=100)\n",
    "pca_mod = pca.fit(X_vec)\n",
    "pca_tr = pca_mod.transform(X_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2VvHIbtLOni"
   },
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH_vOSj6YchL"
   },
   "source": [
    "Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcLYDyD-LoMo"
   },
   "source": [
    "1) Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9n82He1kIuZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_cvec,df['label'],\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8mizP6ybxh8"
   },
   "source": [
    "a) Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQeEAW0PLJpk",
    "outputId": "25e10537-d364-4ae1-dcfc-621ef775f108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "accuracy : 0.8800000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': ['scale', 1, 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'sigmoid']\n",
    "       }\n",
    "svm =SVC()\n",
    "svm_search=GridSearchCV(svm,grid,cv=10,verbose=1)\n",
    "svm_search.fit(X_train,y_train)\n",
    "\n",
    "print(svm_search.best_params_)\n",
    "print(\"accuracy :\",svm_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eJ1qQlxuLmow",
    "outputId": "6844626d-f509-4137-b699-549ca7fafc8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "Precision: [1.         1.         1.         1.         0.76923077 0.9047619\n",
      " 0.95       0.69565217 1.         1.        ]\n",
      "Recall: [0.95 1.   0.85 0.95 1.   0.95 0.95 0.8  0.95 0.8 ]\n",
      "f1-score: [0.97435897 1.         0.91891892 0.97435897 0.86956522 0.92682927\n",
      " 0.95       0.74418605 0.97435897 0.88888889]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "svc =SVC(C = 10, gamma = 0.001, kernel = 'rbf')\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average=None))\n",
    "print('Recall:', recall_score(y_test, y_pred, average=None))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S4RnNZ54b0Gu"
   },
   "source": [
    "b) Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJNcA65zb5SU",
    "outputId": "685fa373-26b5-4b49-c745-a5323967b8bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "{'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "accuracy : 0.88125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': ['scale', 1, 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'sigmoid']\n",
    "       }\n",
    "svm =SVC()\n",
    "svm_search=GridSearchCV(svm,grid,cv=10,verbose=1)\n",
    "svm_search.fit(X_train,y_train)\n",
    "\n",
    "print(svm_search.best_params_)\n",
    "print(\"accuracy :\",svm_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9JXTM-KWcwHs",
    "outputId": "b3b703e9-eb1c-4e7c-95f5-b5635cde08fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.925\n",
      "Precision: [1.         1.         1.         1.         0.76923077 0.95\n",
      " 0.9047619  0.72727273 1.         1.        ]\n",
      "Recall: [0.95 1.   0.95 0.9  1.   0.95 0.95 0.8  0.9  0.85]\n",
      "f1-score: [0.97435897 1.         0.97435897 0.94736842 0.86956522 0.95\n",
      " 0.92682927 0.76190476 0.94736842 0.91891892]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "svc =SVC(C = 10, gamma = 0.001, kernel = 'rbf')\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average=None))\n",
    "print('Recall:', recall_score(y_test, y_pred, average=None))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8K6db9PNL3Vh"
   },
   "source": [
    "2) With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTvkiI60bAhF"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "pca = TruncatedSVD(n_components=100)\n",
    "pca_mod = pca.fit(x_cvec)\n",
    "pca_tr = pca_mod.transform(x_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MEgoEipDbKDM"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_tr,df['label'],\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Pwo4-9kLtpf",
    "outputId": "36ec1fec-9897-4d99-e749-c5d418c513ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "accuracy : 0.89125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': ['scale', 1, 0.1, 0.01, 0.001],\n",
    "        'kernel': ['rbf', 'sigmoid']\n",
    "       }\n",
    "svm =SVC()\n",
    "svm_search=GridSearchCV(svm,grid,cv=10,verbose=1)\n",
    "svm_search.fit(X_train,y_train)\n",
    "\n",
    "print(svm_search.best_params_)\n",
    "print(\"accuracy :\",svm_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pBWE7aL_LwwP",
    "outputId": "30a4b994-6fab-470e-fede-c380d953260c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n",
      "Precision: [1.         0.95238095 0.95238095 0.9047619  0.86956522 1.\n",
      " 0.82608696 0.80952381 0.90909091 0.92857143]\n",
      "Recall: [0.85 1.   1.   0.95 1.   0.85 0.95 0.85 1.   0.65]\n",
      "f1-score: [0.91891892 0.97560976 0.97560976 0.92682927 0.93023256 0.91891892\n",
      " 0.88372093 0.82926829 0.95238095 0.76470588]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "svc =SVC(C = 100, gamma = 0.001, kernel = 'rbf')\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average=None))\n",
    "print('Recall:', recall_score(y_test, y_pred, average=None))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmNvfI1nbGSi"
   },
   "source": [
    "**Data Embedding Test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-AxnNp76i-5o"
   },
   "source": [
    "1) TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ki6WS4zgi5aK"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "pca = TruncatedSVD(n_components=100)\n",
    "pca_mod = pca.fit(X_vec)\n",
    "pca_tr = pca_mod.transform(X_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z5_TI5-cjgxf"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_tr,df['label'],\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSG-ylzcjucc",
    "outputId": "0c03f12c-433f-43fa-8b65-0cffc2260cee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "{'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "accuracy : 0.9562499999999998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': ['scale', 1, 0.1, 0.01, 0.001,0.0001],\n",
    "        'kernel': ['linear','poly','rbf', 'sigmoid']\n",
    "       }\n",
    "svm =SVC()\n",
    "svm_search=GridSearchCV(svm,grid,cv=10,verbose=1)\n",
    "svm_search.fit(X_train,y_train)\n",
    "\n",
    "print(svm_search.best_params_)\n",
    "print(\"accuracy :\",svm_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxTHeNQoj8Uv",
    "outputId": "3b76df04-db10-4760-a050-ddf138106f9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98\n",
      "Precision: [1.         1.         1.         1.         1.         1.\n",
      " 0.90909091 0.90909091 1.         1.        ]\n",
      "Recall: [0.9  1.   1.   0.95 1.   1.   1.   1.   1.   0.95]\n",
      "f1-score: [0.94736842 1.         1.         0.97435897 1.         1.\n",
      " 0.95238095 0.95238095 1.         0.97435897]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "svc =SVC(C = 1, gamma = 'scale', kernel = 'rbf')\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average=None))\n",
    "print('Recall:', recall_score(y_test, y_pred, average=None))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "me2ZDekKkX6N"
   },
   "source": [
    "2) Continuous Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1XrvfU6kXY9",
    "outputId": "390cb0f1-9662-4280-9672-9a2c31e70c04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-86-63b5b5ef79da>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(vectors)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "X=df['text_stem'].tolist()\n",
    "y=np.array(df.label)\n",
    "model = gensim.models.Word2Vec(X,vector_size=100,sg=0)\n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors))\n",
    "X_w2v = W2V(w2v,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B16GnTmnmOaC"
   },
   "outputs": [],
   "source": [
    "for i in range(998):\n",
    "    if X_w2v[i].shape[0]!=100:\n",
    "      print(X_w2v[i].shape[0],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hm_1eV9bmoCA"
   },
   "outputs": [],
   "source": [
    "# X_w2v=np.delete(X_w2v,663)\n",
    "# y=np.delete(y,663)\n",
    "X_w2v=np.delete(X_w2v,847)\n",
    "y=np.delete(y,847)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VuGc1dLZm2Oc",
    "outputId": "e12cd0eb-76ce-4fe6-8814-57025ed0a438"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 100)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec=np.stack(X_w2v)\n",
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxMYXEGwnPKq"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec,y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2dHzCBfPnFgI",
    "outputId": "5e3e006d-e1ed-4268-f9ec-410dc1404f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "{'C': 1000, 'gamma': 1, 'kernel': 'poly'}\n",
      "accuracy : 0.8959651898734176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': ['scale', 1, 0.1, 0.01, 0.001,0.0001],\n",
    "        'kernel': ['linear','poly','rbf', 'sigmoid']\n",
    "       }\n",
    "svm =SVC()\n",
    "svm_search=GridSearchCV(svm,grid,cv=10,verbose=1)\n",
    "svm_search.fit(X_train,y_train)\n",
    "\n",
    "print(svm_search.best_params_)\n",
    "print(\"accuracy :\",svm_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5JqGu3eQpemz",
    "outputId": "ca9fc65f-b27d-488d-e335-7d2bd2e0db21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.905\n",
      "Precision: [0.95       0.9047619  0.94736842 0.94444444 0.9047619  0.88888889\n",
      " 1.         0.94736842 0.86363636 0.73913043]\n",
      "Recall: [0.95 0.95 0.9  0.85 0.95 0.8  0.95 0.9  0.95 0.85]\n",
      "f1-score: [0.95       0.92682927 0.92307692 0.89473684 0.92682927 0.84210526\n",
      " 0.97435897 0.92307692 0.9047619  0.79069767]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "svc =SVC(C = 1000, gamma = 1, kernel = 'poly')\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R44f06pBpl_N"
   },
   "source": [
    "3) Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iLvHWVpapkje",
    "outputId": "ddaf4ded-3409-4667-8bc0-2ec07824af9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-96-63b5b5ef79da>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(vectors)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "y=np.array(df.label)\n",
    "X=df['text_stem'].tolist()\n",
    "model = gensim.models.Word2Vec(X,vector_size=100,sg=1)\n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors))\n",
    "X_w2v = W2V(w2v,X)\n",
    "X_vec=np.stack(X_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZhF9TtvqVyY"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec,y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W6vh6ZmrqsQc",
    "outputId": "684ad3f2-bfd8-4cca-c8a1-2deb7e90156c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "{'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "accuracy : 0.928512658227848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': ['scale', 1, 0.1, 0.01, 0.001,0.0001],\n",
    "        'kernel': ['linear','poly','rbf', 'sigmoid']\n",
    "       }\n",
    "svm =SVC()\n",
    "svm_search=GridSearchCV(svm,grid,cv=10,verbose=1)\n",
    "svm_search.fit(X_train,y_train)\n",
    "\n",
    "print(svm_search.best_params_)\n",
    "print(\"accuracy :\",svm_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zz3Eic-dq1Au",
    "outputId": "caa394b8-854d-45f3-f07c-65e7d5d4b5e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.925\n",
      "Precision: 0.92656223893066\n",
      "Recall: 0.925\n",
      "f1-score: 0.9250678055363548\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "svc =SVC(C = 100, gamma = 'scale', kernel = 'linear')\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred,average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred,average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6CBczdQrEQs"
   },
   "source": [
    "4) Pretrained Model (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1owkyfDI_FeB",
    "outputId": "1f39ad43-e549-4638-afb1-71656c62586f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 120 candidates, totalling 1200 fits\n",
      "{'C': 100, 'gamma': 0.1, 'kernel': 'sigmoid'}\n",
      "accuracy : 0.9525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': ['scale','auto', 1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'kernel': ['linear','rbf', 'poly', 'sigmoid']\n",
    "       }\n",
    "svm =SVC()\n",
    "svm_search=GridSearchCV(svm,grid,cv=10,verbose=1)\n",
    "svm_search.fit(X_train,y_train)\n",
    "\n",
    "print(svm_search.best_params_)\n",
    "print(\"accuracy :\",svm_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MN7WTD6d_Xoz",
    "outputId": "d742cd4f-5805-4719-9e88-d52ecfe512cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.925\n",
      "Precision: [0.94444444 0.94736842 1.         0.95       1.         0.9\n",
      " 0.83333333 0.86956522 0.95       0.88888889]\n",
      "Recall: [0.85 0.9  1.   0.95 0.9  0.9  1.   1.   0.95 0.8 ]\n",
      "f1-score: [0.89473684 0.92307692 1.         0.95       0.94736842 0.9\n",
      " 0.90909091 0.93023256 0.95       0.84210526]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "svc =SVC(C = 100, gamma = 0.1, kernel = 'sigmoid')\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average=None))\n",
    "print('Recall:', recall_score(y_test, y_pred, average=None))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwSX_E76AeWN",
    "outputId": "80d50a3c-a1a9-4c20-ca73-b4363834073b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89        20\n",
      "           1       0.95      0.90      0.92        20\n",
      "           2       1.00      1.00      1.00        20\n",
      "           3       0.95      0.95      0.95        20\n",
      "           4       1.00      0.90      0.95        20\n",
      "           5       0.90      0.90      0.90        20\n",
      "           6       0.83      1.00      0.91        20\n",
      "           7       0.87      1.00      0.93        20\n",
      "           8       0.95      0.95      0.95        20\n",
      "           9       0.89      0.80      0.84        20\n",
      "\n",
      "    accuracy                           0.93       200\n",
      "   macro avg       0.93      0.93      0.92       200\n",
      "weighted avg       0.93      0.93      0.92       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "alSsjMBhBB_D",
    "outputId": "a22ec874-0d2d-49bd-8dd2-7f66b77ebd8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17,  0,  0,  0,  0,  0,  3,  0,  0,  0],\n",
       "       [ 0, 18,  0,  0,  0,  0,  1,  0,  0,  1],\n",
       "       [ 0,  0, 20,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 19,  0,  1,  0,  0,  0,  0],\n",
       "       [ 1,  0,  0,  0, 18,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 18,  0,  0,  1,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0, 20,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 20,  0,  0],\n",
       "       [ 0,  1,  0,  0,  0,  0,  0,  0, 19,  0],\n",
       "       [ 0,  0,  0,  1,  0,  0,  0,  3,  0, 16]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred,labels=list(range(10)))\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zf7I1Ga8ClJU"
   },
   "source": [
    "# **KNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJiAFr_Gjf8x"
   },
   "source": [
    "Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvOUWeoAc44b"
   },
   "source": [
    "1) Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3G814voRBHX6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_cvec,df['label'],\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuzdktC2c9bL"
   },
   "source": [
    "a) Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wER6_ywAc75b",
    "outputId": "3dd062da-0ae0-4c75-879d-9dacd2276448"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "{'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "accuracy : 0.46624999999999994\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "param = {'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "knn_search = GridSearchCV(estimator = knn,  \n",
    "                           param_grid = param,\n",
    "                           cv = 10,\n",
    "                           verbose=1)\n",
    "knn_search.fit(X_train,y_train)\n",
    "print(knn_search.best_params_)\n",
    "print(\"accuracy :\",knn_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "inZgw6EMkcbn",
    "outputId": "0028ff78-34ef-4328-a4c1-f9cab1692278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39\n",
      "Precision: 0.7240477047720735\n",
      "Recall: 0.39\n",
      "f1-score: 0.41521151683205487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "knn =KNeighborsClassifier(n_neighbors=5,weights='distance',metric='minkowski')\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVimkAnLkyKQ"
   },
   "source": [
    "b) Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-_SrHqulgig",
    "outputId": "0db26e5b-5101-4192-c4e9-04f5980c4333"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "{'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "accuracy : 0.4525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "param = {'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "knn_search = GridSearchCV(estimator = knn,  \n",
    "                           param_grid = param,\n",
    "                           cv = 10,\n",
    "                           verbose=1)\n",
    "knn_search.fit(X_train,y_train)\n",
    "print(knn_search.best_params_)\n",
    "print(\"accuracy :\",knn_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fRR1_K1WliHJ",
    "outputId": "8c4b43bf-39c1-4d01-97ad-bbdf5b3c548c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.385\n",
      "Precision: 0.7353326588620707\n",
      "Recall: 0.385\n",
      "f1-score: 0.4102009805636973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "knn =KNeighborsClassifier(n_neighbors=5,weights='distance',metric='minkowski')\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sw5EKw5jk1XY"
   },
   "source": [
    "2) With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SS884G74k0YR"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "pca = TruncatedSVD(n_components=100)\n",
    "pca_mod = pca.fit(x_cvec)\n",
    "pca_tr = pca_mod.transform(x_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OcEWx2O0k65w"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_tr,df['label'],\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKRh1L2gg_EF",
    "outputId": "cc85148b-3d86-4d92-f471-f01b5064b560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "{'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "accuracy : 0.8487500000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "param = {'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "knn_search = GridSearchCV(estimator = knn,  \n",
    "                           param_grid = param,\n",
    "                           cv = 10,\n",
    "                           verbose=1)\n",
    "knn_search.fit(X_train,y_train)\n",
    "print(knn_search.best_params_)\n",
    "print(\"accuracy :\",knn_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vG-vseLJlGEw",
    "outputId": "8aecac67-0ef4-4741-ea71-a3da77ed332b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87\n",
      "Precision: 0.8859884559884561\n",
      "Recall: 0.87\n",
      "f1-score: 0.8693706369582492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "knn =KNeighborsClassifier(n_neighbors=5,weights='distance',metric='minkowski')\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cjaSVovdw3z"
   },
   "source": [
    "Data Embedding Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2CnHA8AdzCT"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec,df['label'],\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrFFbtMDg5N3"
   },
   "source": [
    "1) TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sQtC8RRXmFBB",
    "outputId": "18f33bf3-bebb-4eae-b00e-57cb73e1420a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "{'metric': 'minkowski', 'n_neighbors': 9, 'weights': 'distance'}\n",
      "accuracy : 0.9412499999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "param = {'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "knn_search = GridSearchCV(estimator = knn,  \n",
    "                           param_grid = param,\n",
    "                           cv = 10,\n",
    "                           verbose=1)\n",
    "knn_search.fit(X_train,y_train)\n",
    "print(knn_search.best_params_)\n",
    "print(\"accuracy :\",knn_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2kXWj1nmTpR",
    "outputId": "9a5623e9-ea2a-45c5-e09f-b71f8aa31d98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.925\n",
      "Precision: 0.9278138528138529\n",
      "Recall: 0.925\n",
      "f1-score: 0.9234450038622054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "knn =KNeighborsClassifier(n_neighbors=9,weights='distance',metric='minkowski')\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esNN3cD6hPm2"
   },
   "source": [
    "2) Continuous Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awEw3chvhSiF",
    "outputId": "63b0fffe-f802-4dbd-be5b-eb3acee26b44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-62-63b5b5ef79da>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(vectors)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "X=df['text_stem'].tolist()\n",
    "y=np.array(df.label)\n",
    "model = gensim.models.Word2Vec(X,vector_size=100,sg=0)\n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors))\n",
    "X_w2v = W2V(w2v,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8AiaS9J0hfO-"
   },
   "outputs": [],
   "source": [
    "for i in range(998):\n",
    "    if X_w2v[i].shape[0]!=100:\n",
    "      print(X_w2v[i].shape[0],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FR9PQKQmhpw2"
   },
   "outputs": [],
   "source": [
    "X_w2v=np.delete(X_w2v,663)\n",
    "y=np.delete(y,663)\n",
    "X_w2v=np.delete(X_w2v,847)\n",
    "y=np.delete(y,847)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1wuILbvih0F_",
    "outputId": "e3c5a9c7-577e-4469-d73c-df7aadcf3d33"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 100)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec=np.stack(X_w2v)\n",
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ofwhS19h83X"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec,y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1-06ER_0iA6o",
    "outputId": "ceb0a211-1946-4fe0-f455-dde6ef5e5479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "{'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "accuracy : 0.6604588607594936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "param = {'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "knn_search = GridSearchCV(estimator = knn,  \n",
    "                           param_grid = param,\n",
    "                           cv = 10,\n",
    "                           verbose=1)\n",
    "knn_search.fit(X_train,y_train)\n",
    "print(knn_search.best_params_)\n",
    "print(\"accuracy :\",knn_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p2NxhCFYiJuW",
    "outputId": "5cb7ae63-c2be-42eb-e486-7249adbed842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.645\n",
      "Precision: 0.6626174259177355\n",
      "Recall: 0.645\n",
      "f1-score: 0.6474375677962478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "knn =KNeighborsClassifier(n_neighbors=5,weights='distance',metric='minkowski')\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SadKuoAUiYyW"
   },
   "source": [
    "3) Skip Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3S5FNEMxicZG"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "y=np.array(df.label)\n",
    "X=df['text_stem'].tolist()\n",
    "model = gensim.models.Word2Vec(X,vector_size=100,sg=1)\n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors))\n",
    "X_w2v = W2V(w2v,X)\n",
    "X_vec=np.stack(X_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ymbkYiPij2_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec,y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qKTw-cnVi8pX",
    "outputId": "9a198e0f-56ce-4834-a5a0-94a9d93fd471"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "{'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "accuracy : 0.8922151898734176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "param = {'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "knn_search = GridSearchCV(estimator = knn,  \n",
    "                           param_grid = param,\n",
    "                           cv = 10,\n",
    "                           verbose=1)\n",
    "knn_search.fit(X_train,y_train)\n",
    "print(knn_search.best_params_)\n",
    "print(\"accuracy :\",knn_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOvGTdBVjAFv",
    "outputId": "ed5057fb-99b7-4ca4-f2bf-c6106479a1e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.885\n",
      "Precision: 0.890928267638794\n",
      "Recall: 0.885\n",
      "f1-score: 0.8852600252407697\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "knn =KNeighborsClassifier(n_neighbors=5,weights='distance',metric='minkowski')\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aq1j8cF9dqaj"
   },
   "source": [
    "4) Pretrained Model (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKSRODzkdruL",
    "outputId": "17406c07-d1c9-4dd9-8930-43c71573ab75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 36 candidates, totalling 360 fits\n",
      "{'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "accuracy : 0.9049999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "param = {'n_neighbors' : [5,7,9,11,13,15],\n",
    "               'weights' : ['uniform','distance'],\n",
    "               'metric' : ['minkowski','euclidean','manhattan']}\n",
    "knn_search = GridSearchCV(estimator = knn,  \n",
    "                           param_grid = param,\n",
    "                           cv = 10,\n",
    "                           verbose=1)\n",
    "knn_search.fit(X_train,y_train)\n",
    "print(knn_search.best_params_)\n",
    "print(\"accuracy :\",knn_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxLVk8ZAem8w",
    "outputId": "0ea2f3db-8b14-4a60-fc7d-8c7d648da775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.87\n",
      "Precision: 0.8777093374461796\n",
      "Recall: 0.87\n",
      "f1-score: 0.8706347097179826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "knn =KNeighborsClassifier(n_neighbors=5,weights='uniform',metric='minkowski')\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoVViQUxI1qP"
   },
   "source": [
    "# **Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3bBui-FjaQh"
   },
   "source": [
    "Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QNaLOQhB5K8"
   },
   "source": [
    "1) Without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96_OUDmrB-pB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_cvec,df['label'],\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BrSUHr5NB_p8"
   },
   "source": [
    "a) Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iLMx0NwHCOjv",
    "outputId": "4481f3ee-da49-402f-c5fd-607fc8eea6ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-05}\n",
      "accuracy : 0.86925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV\n",
    "import numpy as np\n",
    "gnb = GaussianNB()\n",
    "cross_val = RepeatedStratifiedKFold(n_splits=5,n_repeats=10,random_state=42)\n",
    "param = {'var_smoothing':[1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07,1.e-08, 1.e-09]}\n",
    "gnb_search = GridSearchCV(estimator=gnb,param_grid=param,cv=cross_val)\n",
    "gnb_search.fit(X_train.toarray(),y_train)\n",
    "print(gnb_search.best_params_)\n",
    "print(\"accuracy :\",gnb_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDXdenEvPyS3",
    "outputId": "16aabb97-f1dd-4832-da4d-ce51ded50041"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.86\n",
      "Precision: 0.866939223057644\n",
      "Recall: 0.86\n",
      "f1-score: 0.8583510527412966\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "gnb =GaussianNB(var_smoothing=1e-05)\n",
    "gnb.fit(X_train.toarray(),y_train)\n",
    "y_pred = gnb.predict(X_test.toarray())\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3yevl6PP4sF"
   },
   "source": [
    "b) Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P-o_nz_-P7MF",
    "outputId": "557aed7e-d628-4a8c-c2b0-cde46273bf06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-05}\n",
      "accuracy : 0.88075\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV\n",
    "import numpy as np\n",
    "gnb = GaussianNB()\n",
    "cross_val = RepeatedStratifiedKFold(n_splits=5,n_repeats=10,random_state=42)\n",
    "param = {'var_smoothing':[1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07,1.e-08, 1.e-09]}\n",
    "gnb_search = GridSearchCV(estimator=gnb,param_grid=param,cv=cross_val)\n",
    "gnb_search.fit(X_train.toarray(),y_train)\n",
    "print(gnb_search.best_params_)\n",
    "print(\"accuracy :\",gnb_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxFHM6s0QK5i",
    "outputId": "ade824b6-a602-4156-d058-ac19aa87ee69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.865\n",
      "Precision: 0.8709739851651617\n",
      "Recall: 0.865\n",
      "f1-score: 0.8643840804182937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "gnb =GaussianNB(var_smoothing=1e-05)\n",
    "gnb.fit(X_train.toarray(),y_train)\n",
    "y_pred = gnb.predict(X_test.toarray())\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8SxCQTsBe-d"
   },
   "source": [
    "2) With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HIxUXgCVACfF"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "pca = TruncatedSVD(n_components=100)\n",
    "pca_mod = pca.fit(x_cvec)\n",
    "pca_tr = pca_mod.transform(x_cvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nW-7ZktC_69H"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_tr,df['label'],\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UgHhEtHwI43E",
    "outputId": "49d28565-979e-4e44-d52e-fd0818793a5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-06}\n",
      "accuracy : 0.59775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV\n",
    "gnb = GaussianNB()\n",
    "cross_val = RepeatedStratifiedKFold(n_splits=5,n_repeats=10,random_state=42)\n",
    "param = {'var_smoothing':[1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07,1.e-08, 1.e-09]}\n",
    "gnb_search = GridSearchCV(estimator=gnb,param_grid=param,cv=cross_val)\n",
    "gnb_search.fit(X_train,y_train)\n",
    "print(gnb_search.best_params_)\n",
    "print(\"accuracy :\",gnb_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2PDRveoPAqar",
    "outputId": "4c970e0d-8fb0-4a99-b4b7-c86a78178628"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.56\n",
      "Precision: 0.6388806588148693\n",
      "Recall: 0.56\n",
      "f1-score: 0.5435804357481224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "gnb =GaussianNB(var_smoothing=1e-06)\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FuyQX79Pa9qz"
   },
   "source": [
    "**Data Embedding Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLlAW5AJS1-R"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec,df['label'],\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDDy2hi2Qh5l"
   },
   "source": [
    "1) TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fv-5958RRbnP",
    "outputId": "a9f9f867-f2cb-4aec-d64e-472382ff0c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 0.01}\n",
      "accuracy : 0.9143749999999998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV\n",
    "import numpy as np\n",
    "gnb = GaussianNB()\n",
    "cross_val = RepeatedStratifiedKFold(n_splits=5,n_repeats=10,random_state=42)\n",
    "param = {'var_smoothing':[1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07,1.e-08, 1.e-09]}\n",
    "gnb_search = GridSearchCV(estimator=gnb,param_grid=param,cv=cross_val)\n",
    "gnb_search.fit(X_train.toarray(),y_train)\n",
    "print(gnb_search.best_params_)\n",
    "print(\"accuracy :\",gnb_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x9DPi9lPRcOl",
    "outputId": "b8881062-80d8-47ec-f2af-9eeb0aeb9dc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "Precision: 0.8928019483918662\n",
      "Recall: 0.89\n",
      "f1-score: 0.8889892413169123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "gnb =GaussianNB(var_smoothing=0.01)\n",
    "gnb.fit(X_train.toarray(),y_train)\n",
    "y_pred = gnb.predict(X_test.toarray())\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LghKEm-8TAu2"
   },
   "source": [
    "2) Continuous Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ce9WwR37TFbm",
    "outputId": "0ffad2ec-67f2-468f-bb48-b0cca32e0afc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-63b5b5ef79da>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(vectors)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "X=df['text_stem'].tolist()\n",
    "y=np.array(df.label)\n",
    "model = gensim.models.Word2Vec(X,vecotr_size=100,sg=0)\n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors))\n",
    "X_w2v = W2V(w2v,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oa8Gdv3nU5Ad"
   },
   "outputs": [],
   "source": [
    "for i in range(998):\n",
    "    if X_w2v[i].shape[0]!=100:\n",
    "      print(X_w2v[i].shape[0],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnEGfbd0VCds"
   },
   "outputs": [],
   "source": [
    "X_w2v=np.delete(X_w2v,663)\n",
    "y=np.delete(y,663)\n",
    "X_w2v=np.delete(X_w2v,847)\n",
    "y=np.delete(y,847)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-G_y8QFuVLGV"
   },
   "outputs": [],
   "source": [
    "X_vec=np.stack(X_w2v)\n",
    "X_vec.shape\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec,y,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=42,\n",
    "                                                   stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVb6npIFVcBu",
    "outputId": "ecbc20f4-3514-4164-b80e-76dfa15e1a79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-06}\n",
      "accuracy : 0.49133569182389936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV\n",
    "import numpy as np\n",
    "gnb = GaussianNB()\n",
    "cross_val = RepeatedStratifiedKFold(n_splits=5,n_repeats=10,random_state=42)\n",
    "param = {'var_smoothing':[1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07,1.e-08, 1.e-09]}\n",
    "gnb_search = GridSearchCV(estimator=gnb,param_grid=param,cv=cross_val)\n",
    "gnb_search.fit(X_train,y_train)\n",
    "print(gnb_search.best_params_)\n",
    "print(\"accuracy :\",gnb_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GkeMNonvVfGN",
    "outputId": "eb520235-91b2-4ad1-80d5-cc216ad58b5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.495\n",
      "Precision: 0.5473283585783586\n",
      "Recall: 0.495\n",
      "f1-score: 0.49424511945051103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "gnb =GaussianNB(var_smoothing=1e-06)\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lT4oL4bRWbWA"
   },
   "source": [
    "3) Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h3qOXeqOWSV2",
    "outputId": "211bacb1-42a6-4441-96dc-0dc7b474bdc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-63b5b5ef79da>:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(vectors)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "y=np.array(df.label)\n",
    "X=df['text_stem'].tolist()\n",
    "model = gensim.models.Word2Vec(X,vector_size=100,sg=1)\n",
    "w2v = dict(zip(model.wv.index_to_key, model.wv.vectors))\n",
    "X_w2v = W2V(w2v,X)\n",
    "X_vec=np.stack(X_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duqACm_zWpaN",
    "outputId": "acc27a95-22c3-478e-e257-c4961077e4fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 1e-07}\n",
      "accuracy : 0.8378522012578616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV\n",
    "import numpy as np\n",
    "gnb = GaussianNB()\n",
    "cross_val = RepeatedStratifiedKFold(n_splits=5,n_repeats=10,random_state=42)\n",
    "param = {'var_smoothing':[1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07,1.e-08, 1.e-09]}\n",
    "gnb_search = GridSearchCV(estimator=gnb,param_grid=param,cv=cross_val)\n",
    "gnb_search.fit(X_train,y_train)\n",
    "print(gnb_search.best_params_)\n",
    "print(\"accuracy :\",gnb_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xFaxiaCXHPT",
    "outputId": "481afb68-c764-4255-f077-b705709e6009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "Precision: 0.8609174451279713\n",
      "Recall: 0.84\n",
      "f1-score: 0.842469723987054\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "gnb =GaussianNB(var_smoothing=1e-07)\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HxRnbQEXYs6"
   },
   "source": [
    "4) Pretrained Model (Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "goAmr3G6XRRm",
    "outputId": "1392e4c7-06b4-4a6c-a5ff-2c046668dee3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 0.001}\n",
      "accuracy : 0.8853749999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,GridSearchCV\n",
    "import numpy as np\n",
    "gnb = GaussianNB()\n",
    "cross_val = RepeatedStratifiedKFold(n_splits=5,n_repeats=10,random_state=42)\n",
    "param = {'var_smoothing':[1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06, 1.e-07,1.e-08, 1.e-09]}\n",
    "gnb_search = GridSearchCV(estimator=gnb,param_grid=param,cv=cross_val)\n",
    "gnb_search.fit(X_train,y_train)\n",
    "print(gnb_search.best_params_)\n",
    "print(\"accuracy :\",gnb_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KkEsXmaYCuK",
    "outputId": "b02541a2-a735-4c16-d198-a6cbfd50ad57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.845\n",
      "Precision: 0.8599006798591197\n",
      "Recall: 0.845\n",
      "f1-score: 0.8471900098749756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, recall_score, roc_auc_score, precision_score\n",
    "gnb =GaussianNB(var_smoothing=0.001)\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Recall:', recall_score(y_test, y_pred, average='weighted'))\n",
    "print('f1-score:', f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejZPRqjVaz_o"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RywcCYB1zhhv"
   },
   "source": [
    "# Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QNXGbNLnzhh0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "gAi7P0Ngzhh5",
    "outputId": "e0518ef2-509a-4bf3-a14b-94c3761246ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-066eba5f-00b1-429c-890d-f778acad08b7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>word_id</th>\n",
       "      <th>word_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198712</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>3406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198713</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198714</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198715</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>1529</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198716</th>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198717 rows × 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-066eba5f-00b1-429c-890d-f778acad08b7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-066eba5f-00b1-429c-890d-f778acad08b7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-066eba5f-00b1-429c-890d-f778acad08b7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        Class_id  document_id  word_id  word_frequency\n",
       "0              1            1        1               4\n",
       "1              1            1        2               0\n",
       "2              1            1        3               0\n",
       "3              1            1        4               1\n",
       "4              1            1        5               3\n",
       "...          ...          ...      ...             ...\n",
       "198712        10         1000     3406               0\n",
       "198713        10         1000       85               0\n",
       "198714        10         1000      197               0\n",
       "198715        10         1000     1529               0\n",
       "198716        10         1000     1337               0\n",
       "\n",
       "[198717 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df=pd.read_csv(\"lp_smoothing.csv\")\n",
    "data_df.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sUZbKFfFzhh6",
    "outputId": "06a95295-2d31-4806-f28f-ae5020cd1b9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.1,\n",
       " 2: 0.1,\n",
       " 3: 0.1,\n",
       " 4: 0.1,\n",
       " 5: 0.1,\n",
       " 6: 0.1,\n",
       " 7: 0.1,\n",
       " 8: 0.1,\n",
       " 9: 0.1,\n",
       " 10: 0.1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_class = {1: 0.1,2: 0.1,3: 0.1,4: 0.1,5: 0.1,6: 0.1,7: 0.1,8: 0.1,9: 0.1,10: 0.1}\n",
    "prob_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dC58rLVAzhh6"
   },
   "source": [
    "<h3>Applying laplace smoothing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdhfDDjhzhh6"
   },
   "outputs": [],
   "source": [
    "#with laplace smoothing\n",
    "a = 1\n",
    "\n",
    "#probability of each word given class\n",
    "prob_word_class = data_df.groupby(['Class_id','word_id'])\n",
    "prob_class = data_df.groupby(['Class_id'])\n",
    "prob_word =  (prob_word_class['word_frequency'].sum() + a) / (prob_class['word_frequency'].sum() + len(total_words))\n",
    "\n",
    "prob_word = prob_word.unstack()\n",
    "\n",
    "for c in range(1,11):\n",
    "     prob_word.loc[c,:] = prob_word.loc[c,:].fillna(a/(prob_class['word_frequency'].sum()[c] + len(total_words)))\n",
    "\n",
    "prob_dict_lp = prob_word.to_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CCIDEhgzhh7"
   },
   "source": [
    "<h4>probability of each word in a class</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4P9xpLb0zhh7",
    "outputId": "4e02a37a-469e-44f5-cde2-3f4dbeba6e3a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>31317</th>\n",
       "      <th>31318</th>\n",
       "      <th>31319</th>\n",
       "      <th>31320</th>\n",
       "      <th>31321</th>\n",
       "      <th>31322</th>\n",
       "      <th>31323</th>\n",
       "      <th>31324</th>\n",
       "      <th>31325</th>\n",
       "      <th>31326</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.024572</td>\n",
       "      <td>0.004502</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.018886</td>\n",
       "      <td>0.045825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.011814</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.007406</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>0.041708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.008919</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.175242</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.007639</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.017018</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.040104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.012002</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.211775</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.013301</td>\n",
       "      <td>0.027785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.023610</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.008623</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.040771</td>\n",
       "      <td>0.090361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.023604</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.008046</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.051508</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.011888</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.086743</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.010475</td>\n",
       "      <td>0.022731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.009287</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.342062</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.014555</td>\n",
       "      <td>0.020954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>0.041774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31326 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "word_id      1         2         3         4         5         6      \\\n",
       "Class_id                                                               \n",
       "1         0.000143  0.000108  0.000448  0.024572  0.004502  0.000143   \n",
       "2         0.000022  0.000067  0.000022  0.011814  0.002349  0.000022   \n",
       "3         0.000020  0.000480  0.000040  0.008919  0.000880  0.000020   \n",
       "4         0.000022  0.000022  0.000022  0.017018  0.002807  0.000022   \n",
       "5         0.000014  0.000390  0.000014  0.012002  0.002236  0.000014   \n",
       "6         0.000012  0.000024  0.000012  0.023610  0.002003  0.000012   \n",
       "7         0.000018  0.000018  0.000018  0.023604  0.005573  0.000129   \n",
       "8         0.000019  0.000116  0.000019  0.011888  0.002130  0.000019   \n",
       "9         0.000012  0.000153  0.000012  0.009287  0.001897  0.000012   \n",
       "10        0.000021  0.000021  0.000021  0.017500  0.002051  0.000043   \n",
       "\n",
       "word_id      7         8         9         10     ...     31317     31318  \\\n",
       "Class_id                                          ...                       \n",
       "1         0.007443  0.000143  0.018886  0.045825  ...  0.000018  0.000018   \n",
       "2         0.007406  0.000022  0.012754  0.041708  ...  0.000022  0.000022   \n",
       "3         0.175242  0.000020  0.007639  0.016558  ...  0.000020  0.000020   \n",
       "4         0.007537  0.000022  0.010474  0.040104  ...  0.000022  0.000022   \n",
       "5         0.211775  0.000260  0.013301  0.027785  ...  0.000014  0.000014   \n",
       "6         0.008623  0.000024  0.040771  0.090361  ...  0.000012  0.000012   \n",
       "7         0.008046  0.000074  0.016812  0.051508  ...  0.000018  0.000018   \n",
       "8         0.086743  0.000077  0.010475  0.022731  ...  0.000019  0.000019   \n",
       "9         0.342062  0.000012  0.014555  0.020954  ...  0.000012  0.000012   \n",
       "10        0.007030  0.000021  0.015898  0.041774  ...  0.000021  0.000021   \n",
       "\n",
       "word_id      31319     31320     31321     31322     31323     31324  \\\n",
       "Class_id                                                               \n",
       "1         0.000018  0.000018  0.000018  0.000018  0.000018  0.000018   \n",
       "2         0.000022  0.000022  0.000022  0.000022  0.000022  0.000022   \n",
       "3         0.000020  0.000020  0.000020  0.000020  0.000020  0.000020   \n",
       "4         0.000022  0.000022  0.000022  0.000022  0.000022  0.000022   \n",
       "5         0.000014  0.000014  0.000014  0.000014  0.000014  0.000014   \n",
       "6         0.000012  0.000012  0.000012  0.000012  0.000012  0.000012   \n",
       "7         0.000018  0.000018  0.000018  0.000018  0.000018  0.000018   \n",
       "8         0.000019  0.000019  0.000019  0.000019  0.000019  0.000019   \n",
       "9         0.000012  0.000012  0.000012  0.000012  0.000012  0.000012   \n",
       "10        0.000021  0.000021  0.000021  0.000021  0.000021  0.000021   \n",
       "\n",
       "word_id      31325     31326  \n",
       "Class_id                      \n",
       "1         0.000018  0.000018  \n",
       "2         0.000022  0.000022  \n",
       "3         0.000020  0.000020  \n",
       "4         0.000022  0.000022  \n",
       "5         0.000014  0.000014  \n",
       "6         0.000012  0.000012  \n",
       "7         0.000018  0.000018  \n",
       "8         0.000019  0.000019  \n",
       "9         0.000012  0.000012  \n",
       "10        0.000021  0.000085  \n",
       "\n",
       "[10 rows x 31326 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a8QqPYAzhh7"
   },
   "source": [
    "<h3>Probability without laplace smoothing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPJfdlYfzhh8"
   },
   "outputs": [],
   "source": [
    "#without laplace smoothing\n",
    "\n",
    "#probability of each word given class\n",
    "prob_word_class = data_df.groupby(['Class_id','word_id'])\n",
    "prob_class = data_df.groupby(['Class_id'])\n",
    "prob_word =  (prob_word_class['word_frequency'].sum()) / (prob_class['word_frequency'].sum())\n",
    "\n",
    "prob_word = prob_word.unstack()\n",
    "\n",
    "for c in range(1,11):\n",
    "  prob_word.loc[c,:] = prob_word.loc[c,:]\n",
    "\n",
    "prob_dict_wlp = prob_word.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oW4eJHsszhh8"
   },
   "source": [
    "<h4>probability of each word in a class</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "obhqoOkizhh8",
    "outputId": "7202bd6c-6679-4875-caa3-1e5d4667a6cc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>word_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>31317</th>\n",
       "      <th>31318</th>\n",
       "      <th>31319</th>\n",
       "      <th>31320</th>\n",
       "      <th>31321</th>\n",
       "      <th>31322</th>\n",
       "      <th>31323</th>\n",
       "      <th>31324</th>\n",
       "      <th>31325</th>\n",
       "      <th>31326</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.056040</td>\n",
       "      <td>0.010234</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.043064</td>\n",
       "      <td>0.104548</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039428</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042571</td>\n",
       "      <td>0.139384</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.023824</td>\n",
       "      <td>0.002302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020397</td>\n",
       "      <td>0.044274</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052540</td>\n",
       "      <td>0.008612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032312</td>\n",
       "      <td>0.123907</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.386361</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.024241</td>\n",
       "      <td>0.050667</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038223</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013948</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.066019</td>\n",
       "      <td>0.146342</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055906</td>\n",
       "      <td>0.013167</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.019029</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.039808</td>\n",
       "      <td>0.122047</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030166</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220412</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.026573</td>\n",
       "      <td>0.057724</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014703</td>\n",
       "      <td>0.002989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023054</td>\n",
       "      <td>0.033198</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052866</td>\n",
       "      <td>0.006140</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.021198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048019</td>\n",
       "      <td>0.126284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31326 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "word_id      1         2         3         4         5         6      \\\n",
       "Class_id                                                               \n",
       "1         0.000287  0.000205  0.000982  0.056040  0.010234  0.000287   \n",
       "2              NaN  0.000150       NaN  0.039428  0.007781  0.000000   \n",
       "3              NaN  0.001231  0.000054  0.023824  0.002302       NaN   \n",
       "4              NaN  0.000000  0.000000  0.052540  0.008612       NaN   \n",
       "5              NaN  0.000684       NaN  0.021872  0.004053       NaN   \n",
       "6              NaN  0.000020       NaN  0.038223  0.003225       NaN   \n",
       "7              NaN  0.000000  0.000000  0.055906  0.013167  0.000262   \n",
       "8              NaN  0.000246  0.000000  0.030166  0.005364       NaN   \n",
       "9              NaN  0.000224       NaN  0.014703  0.002989       NaN   \n",
       "10             NaN  0.000000       NaN  0.052866  0.006140  0.000065   \n",
       "\n",
       "word_id      7         8         9         10     ...  31317  31318  31319  \\\n",
       "Class_id                                          ...                        \n",
       "1         0.016947  0.000287  0.043064  0.104548  ...    NaN    NaN    NaN   \n",
       "2         0.024690  0.000000  0.042571  0.139384  ...    NaN    NaN    NaN   \n",
       "3         0.469083  0.000000  0.020397  0.044274  ...    NaN    NaN    NaN   \n",
       "4         0.023233  0.000000  0.032312  0.123907  ...    NaN    NaN    NaN   \n",
       "5         0.386361  0.000447  0.024241  0.050667  ...    NaN    NaN    NaN   \n",
       "6         0.013948  0.000020  0.066019  0.146342  ...    NaN    NaN    NaN   \n",
       "7         0.019029  0.000131  0.039808  0.122047  ...    NaN    NaN    NaN   \n",
       "8         0.220412  0.000148  0.026573  0.057724  ...    NaN    NaN    NaN   \n",
       "9         0.542231  0.000000  0.023054  0.033198  ...    NaN    NaN    NaN   \n",
       "10        0.021198  0.000000  0.048019  0.126284  ...    0.0    0.0    0.0   \n",
       "\n",
       "word_id   31320  31321  31322  31323  31324  31325     31326  \n",
       "Class_id                                                      \n",
       "1           NaN    NaN    NaN    NaN    NaN    NaN       NaN  \n",
       "2           NaN    NaN    NaN    NaN    NaN    NaN       NaN  \n",
       "3           NaN    NaN    NaN    NaN    NaN    NaN       NaN  \n",
       "4           NaN    NaN    NaN    NaN    NaN    NaN       NaN  \n",
       "5           NaN    NaN    NaN    NaN    NaN    NaN       NaN  \n",
       "6           NaN    NaN    NaN    NaN    NaN    NaN       NaN  \n",
       "7           NaN    NaN    NaN    NaN    NaN    NaN       NaN  \n",
       "8           NaN    NaN    NaN    NaN    NaN    NaN       NaN  \n",
       "9           NaN    NaN    NaN    NaN    NaN    NaN       NaN  \n",
       "10          0.0    0.0    0.0    0.0    0.0    0.0  0.000194  \n",
       "\n",
       "[10 rows x 31326 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dict_wlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWwBNco0zhh-"
   },
   "source": [
    "<h3>Calculating probability of every class given document of test dataset and then assigning class to every document</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiQa_ia5zhh-"
   },
   "outputs": [],
   "source": [
    "def assign_class(Pr_dict , dict):\n",
    "    result = []\n",
    "    for doc_id in range(1, len(dict)+1):\n",
    "        prob_dict = {}\n",
    "        for class_id in range(1,len(count_perclass) + 1):\n",
    "            prob_dict[class_id] = 1\n",
    "            for word_id in dict[doc_id]: \n",
    "                prob=Pr_dict[word_id][class_id]\n",
    "                if prob != 0:            \n",
    "                    prob_dict[class_id]+=(np.log(1+ dict[doc_id][word_id]))*np.log(prob)\n",
    "                else:\n",
    "                    prob_dict[class_id] += 0       \n",
    "#calculating final probability of each word      \n",
    "            prob_dict[class_id] +=  np.log(prob_class[class_id])                          \n",
    "            \n",
    "#finding maximum value of probability\n",
    "        max_probability = max(prob_dict, key=prob_dict.get)\n",
    "        result.append(max_probability)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bk2o1mAUzhh-"
   },
   "source": [
    "<h2>Creating a new dictionary to store the frequency, doc_id and word_count and to provide a way to see the results with and without laplace smoothing </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OeXGrCLMzhh-"
   },
   "outputs": [],
   "source": [
    "def algorithm(df , laplace_smoothing= False):\n",
    "\n",
    "    df_dict = df.to_dict()\n",
    "#new_dict is a dictionary containing keys as document id's and values as dictionaries containing wordId as keys\n",
    "#and word frequency as values.\n",
    "    new_dict = {}\n",
    "    \n",
    "    for ID in range(len(df_dict['document_id'])):\n",
    "        doc_id = df_dict['document_id'][ID]\n",
    "        word_id = df_dict['word_id'][ID]\n",
    "        frequency = df_dict['word_frequency'][ID]\n",
    "        new_dict[doc_id][word_id] = df_dict['word_frequency'][ID] \n",
    "    if laplace_smoothing:\n",
    "      return assign_class(prob_dict_wlp , new_dict) \n",
    "    return assign_class(prob_word , new_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xnk0-6pYzhh-"
   },
   "source": [
    "<h3>Testing our model against the training dataset and calculating the error</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bR8dCTe6zhh-",
    "outputId": "9c04b48f-8523-4d07-8d29-913fcc4d32eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error without laplace:\t\t 90.00000 %\n",
      "Error with laplace:\t\t 8.50000 %\n"
     ]
    }
   ],
   "source": [
    "test_data_df = data_df\n",
    "\n",
    "classification_withLaplace = algorithm(test_data_df , True)\n",
    "classification_withoutLaplace = algorithm(test_data_df , False)\n",
    "\n",
    "#training dataframe for verification of our model\n",
    "\n",
    "training_data = list(class_doc[0]) \n",
    "correctness = 0\n",
    "correctness_a = 0\n",
    "\n",
    "for x,y in zip(classification_withoutLaplace, training_data):\n",
    "    if x != y:\n",
    "        correctness +=1\n",
    "    else:\n",
    "        pass   \n",
    "print(\"Error without laplace:\\t\\t\", \"{0:.5f}\".format(correctness/ len(training_data) *100), \"%\")\n",
    "\n",
    "for x,y in zip(classification_withLaplace, training_data):\n",
    "    if x != y:\n",
    "        correctness_a +=1\n",
    "    else:\n",
    "        pass \n",
    "print(\"Error with laplace:\\t\\t\", \"{0:.5f}\".format(correctness_a/ len(training_data) *100) , \"%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "C3v0uCtb9muT",
    "P2VvHIbtLOni"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
